{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d8cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2018\\AppData\\Local\\Temp\\ipykernel_19960\\151104204.py:77: RuntimeWarning: overflow encountered in power\n",
      "  return 1/(1+math.e**(-X))\n",
      "C:\\Users\\2018\\AppData\\Local\\Temp\\ipykernel_19960\\151104204.py:89: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_value = - np.sum(np.dot(y_new.T,np.log(y_pred)+ np.dot((1-y_new).T,np.log(1-y_pred)))) /(len(y_pred))\n",
      "C:\\Users\\2018\\AppData\\Local\\Temp\\ipykernel_19960\\151104204.py:109: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))+term\n",
      "C:\\Users\\2018\\AppData\\Local\\Temp\\ipykernel_19960\\151104204.py:117: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990642545227698 accuracy per iteration\n",
      "0.9975046787273861 accuracy per iteration\n",
      "0.9993761696818465 accuracy per iteration\n",
      "0.9990642545227698 accuracy per iteration\n",
      "0.9992202121023082 accuracy per iteration\n",
      "0.9992202121023082 accuracy per iteration\n",
      "0.9990642545227698 accuracy per iteration\n",
      "0.9996880848409233 accuracy per iteration\n",
      "0.9984404242046163 accuracy per iteration\n",
      "0.9940726875682421 accuracy per iteration\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 1]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 2]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 3]\n",
      "Accuracy: 0.9986\n",
      "[SPLIT 4]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 5]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 6]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 7]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 8]\n",
      "Accuracy: 0.9985\n",
      "[SPLIT 9]\n",
      "[[12801     0]\n",
      " [   23     0]]\n",
      "0.9982064878353087\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnMUlEQVR4nO3deXxV1bn/8c9DmGcJIAgEMEAZBTQMtVVERaEW1JqCI6jci9XidWh92V6tV7331lrb3l/bq/dWqwUVAbFF01YFfwWHVmVQQBkqP5QpoBLDIHMS8vz+2DvpIWQ4IdnnJDnf9+t1Xpy99zprPTsJebL22nstc3dERCR1NUp2ACIiklxKBCIiKU6JQEQkxSkRiIikOCUCEZEU1zjZAVRXx44dvVevXskOQ0SkXnnvvfe+cPdO5R2rd4mgV69erFy5MtlhiIjUK2a2taJjujQkIpLilAhERFKcEoGISIpTIhARSXFKBCIiKS6yRGBmT5nZLjNbW8FxM7NfmdkmM/vAzM6MKhYREalYlD2CWcD4So5PAPqGrxnA/0QYi4iIVCCyRODubwK7KylyKfC0B94F2ptZ16jiERGpr9yd//zzetbv/DKS+pM5RtAN2B6znRvuO4GZzTCzlWa2Mi8vLyHBiYjUFW9/nM8Tb23mo88bXiKIm7s/7u5Z7p7VqVO5T0iLiDRYc5Zt5ZSWTZgwOJqLJslMBDuAHjHb3cN9IiIS2vXlERav+5xvZ/WgeZO0SNpIZiLIAaaGdw+NBva5+6dJjEdEpM6Zv2I7RcXOVSMzImsjsknnzGwucB7Q0cxygX8DmgC4+/8CLwPfADYBh4AboopFRKQ+OlbszF2+jXP6dqR3x1aRtRNZInD3q6o47sB3o2pfRKS+W/r3Xezcd4T7Jg6MtJ16MVgsIpKK5izbyqltm3HBgFMjbUeJQESkDtq++xCvb8xjyogMmqRF+6taiUBEpA6au3wbBlw1skeVZWtKiUBEpI4pKCrm+ZXbuWDAqXRt1yLy9pQIRETqmEXrPuOLAwVcMyq6W0ZjKRGIiNQxz767lR4dWnBu38TMpKBEICJSh2zatZ9lm3dz9cieNGpkCWlTiUBEpA559t1tNEkzJmd1T1ibSgQiInXE4YJj/P79XCYM7kp662YJa1eJQESkjvjjmp3sP1LEtaN7JrRdJQIRkTpizrKt9O3cmhG9Tklou0oEIiJ1wIe5+1iTu49rRmVglphB4hJKBCIidcCcZVtp0SSNb52VuEHiEkoEIiJJ9uWRQl5avZNJQ0+jbfMmCW9fiUBEJMkWvr+Dw4XHEj5IXEKJQEQkidydOcu2ckb3dgzp3i4pMSgRiIgk0Yote9j4+QGuHZWc3gAoEYiIJNWcZVtp07wx3xzaNWkxKBGIiCRJ/oGjvPLhZ1xxZndaNo1s5eAqKRGIiCTJgvdyKThWnLDppiuiRCAikgTFxc5zy7YxsncH+p7aJqmxKBGIiCTBW5u+YNvuQ0m7ZTSWEoGISBI8++5W0ls15eJBpyY7FCUCEZFE+3TfYf6y4XMmj+hBs8ZpyQ5HiUBEJNHmLt+OA1ePTO4gcQklAhGRBCo8Vsy85dsY068TPTq0THY4gBKBiEhC/WXD5+zaf5RrkvgkcVlKBCIiCfT0O1vp2q45Y7/SKdmhlFIiEBFJkC8OHOXtj/OZMLgrjdPqzq/fuhOJiEgDt/9IEQB9T22d5EiOp0QgIpJgLZok/5bRWJEmAjMbb2YfmdkmM/tBOcczzGypma0ysw/M7BtRxiMiIieKLBGYWRrwKDABGAhcZWYDyxS7F3je3YcDVwKPRRWPiIiUL8oewUhgk7t/4u4FwDzg0jJlHGgbvm8H7IwwHhERKUeUiaAbsD1mOzfcF+t+4FozywVeBm4tryIzm2FmK81sZV5eXhSxioikrGQPFl8FzHL37sA3gGfM7ISY3P1xd89y96xOnerOvbciIg1BlIlgB9AjZrt7uC/WdOB5AHd/B2gOdIwwJhGRpNh7qIDZb29JdhjlijIRrAD6mllvM2tKMBicU6bMNuACADMbQJAIdO1HRBqcNzbmMevtLbRp3pheHVslO5zjRLZIprsXmdlMYBGQBjzl7uvM7EFgpbvnAN8DnjCzOwgGjq93d48qJhGRZCkOf7X9cebXUycRALj7ywSDwLH77ot5vx74WpQxiIhI5ZI9WCwiIkmmRCAikuKUCEREUpwSgYhIilMiEBFJcUoEIiIRe/2jXfzoxXUANDJLcjQnUiIQEYnYxs/3c+BoEbdd0Jfup7RIdjgnUCIQEUmQGeeeTqNG6hGIiEgdo0QgIpLi4k4EZtYyykBERCQ5qkwEZna2ma0H/h5uDzUzLSkpItJAxNMj+C/gYiAfwN3XAOdGGZSIiCROXLOPuvt2O/7e12PRhCMiklz7DhXy1qY8imtxQvx1O7+svcoiEE8i2G5mZwNuZk2A24AN0YYlIpIcv/3rJ/x6yaZar7dV0zSapNXN+3PiSQTfAX5JsPD8DmAxcEuUQYmIJMvRomKaNW7En//lnFqtt0OrpjRtXH8TwVfc/ZrYHWb2NeBv0YQkIpJcjczo07l1ssNImHjS06/j3CciIvVQhT0CM/sqcDbQyczujDnUlmANYhERaQAquzTUFGgdlmkTs/9LIDvKoEREJHEqTATu/gbwhpnNcvetCYxJREQSKJ7B4kNm9ggwCGhestPdz48sKhERSZh4EsEcYD7wTYJbSacBeVEGJSKSSO7Ovy5cyyd5B9i2+1Cyw0m4eO4aSnf3J4FCd3/D3W8E1BsQkQbjWLEzd/k2duw9TEaHllw9KiPZISVUPD2CwvDfT83sEmAn0CG6kEREkmNKVg9uvaBvssNIuHgSwX+YWTvgewTPD7QFbo8yKBERSZwqE4G7/yl8uw8YC6VPFouISANQ2QNlacBkgjmGXnX3tWb2TeBfgRbA8MSEKCIiUaqsR/Ak0ANYDvzKzHYCWcAP3P3FBMQmIiIJUFkiyALOcPdiM2sOfAZkunt+YkITEZFEqCwRFLh7MYC7HzGzT6qbBMxsPMEU1mnAb939J+WUmQzcDziwxt2vrk4bIiIlDhUUsXPvkWp/7lhtrkJTD1WWCPqb2QfhewMyw20D3N3PqKzicIzhUWAckAusMLMcd18fU6Yv8EPga+6+x8w61+BcRCTFXf+7FSzfvPukP9+sSd1cLyBqlSWCATWseySwyd0/ATCzecClwPqYMv8MPOruewDcfVcN2xSRFLb3UAFDe7Rn+td7V/uzaWac269jBFHVfZVNOlfTiea6AdtjtnOBUWXK9AMws78RXD66391fLVuRmc0AZgBkZKTWE38iUj2ntWvOpKGnJTuMeiXZ/aDGQF/gPOAq4Akza1+2kLs/7u5Z7p7VqVOnxEYoItLARZkIdhDcflqie7gvVi6Q4+6F7r4Z2EiQGEREJEHiSgRm1sLMvlLNulcAfc2st5k1Ba4EcsqUeZGgN4CZdSS4VPRJNdsREZEaqDIRmNlEYDXwarg9zMzK/kI/gbsXATOBRcAG4Hl3X2dmD5rZpLDYIiDfzNYDS4G79JyCiEhixTPp3P0EdwC9DuDuq80sriF5d38ZeLnMvvti3jtwZ/gSEZEkiOfSUKG77yuzL7WfvhCROmnHnsPJDqFeiqdHsM7MrgbSwgfA/gV4O9qwRESqr0PrpuzcV/0ni1NdPD2CWwnWKz4KPEcwHfXtEcYkInJSGjdqRM8OLZMdRr0TT4+gv7vfA9wTdTAiIpJ48fQIfm5mG8zs381scOQRiYhIQlWZCNx9LMHKZHnAb8zsQzO7N/LIREQkIeJ6oMzdP3P3XwHfIXim4L7KPyEiIvVFPA+UDTCz+83sQ4LF698mmC5CREQagHgGi58C5gMXu/vOiOMREZEEqzIRuPtXExGIiEhNbf7iIAO7tk12GPVOhYnAzJ5398nhJaHYJ4njWqFMRCTROrZuypdHCpMdRr1TWY/gtvDfbyYiEBGRmmpkRvdTWiQ7jHqnwsFid/80fHuLu2+NfQG3JCY8ERGJWjy3j44rZ9+E2g5ERESSo7IxgpsJ/vI/3cw+iDnUBvhb1IGJiEhiVDZG8BzwCvAQ8IOY/fvdfXekUYmISMJUlgjc3beY2XfLHjCzDkoGIiINQ1U9gm8C7xHcPmoxxxw4PcK4RCRF/L/P97Mmt+zaVyfncOGxWqkn1VSYCNz9m+G/cS1LKSJyMu7+/Qe8v21vrdWX3qpZrdWVKqp8stjMvgasdveDZnYtcCbwf9x9W+TRiUiDV3CsmLMz03n4itp5RrVbez1HUF3xzDX0P8BQMxsKfA/4LfAMMCbKwEQkdbRokkYPrSyWNPE8R1Dk7g5cCvy3uz9KcAupiIg0APH0CPab2Q+B64BzzKwR0CTasEREJFHi6RFMIVi4/kZ3/4xgLYJHIo1KREQSJp6lKj8D5gDtzOybwBF3fzryyEREJCHiWaFsMrAc+DYwGVhmZtlRByYiIokRzxjBPcAId98FYGadgP8LvBBlYCKSPGt37OPBP66nsLg48rY+3nWQU9s0j7wdqVg8iaBRSRII5RPnovciUj+t2LKb5Vt289XT02mcZlV/oAayep3CpcO7RdqGVC6eRPCqmS0C5obbU4CXowtJROqK/7n2TNq3bJrsMCRi8axZfJeZfQv4erjrcXdfGG1YIiKSKJWtR9AX+BmQCXwIfN/ddyQqMBERSYzKrvU/BfwJuIJgBtJfV7dyMxtvZh+Z2SYz+0El5a4wMzezrOq2ISIiNVPZpaE27v5E+P4jM3u/OhWbWRrwKMFSl7nACjPLcff1Zcq1AW4DllWnfhERqR2VJYLmZjacf6xD0CJ2292rSgwjgU3u/gmAmc0jmK9ofZly/w48DNxVzdhFRKQWVJYIPgV+EbP9Wcy2A+dXUXc3YHvMdi4wKraAmZ0J9HD3P5tZhYnAzGYAMwAyMjKqaFYkdezYe5h9hwprvd7PvjxS63VK3VXZwjRjo2w4nLzuF8D1VZV198eBxwGysrI8yrhE6ovPvzzC136yJLL6Gxk0SdMjQ6kgnucITtYOoEfMdvdwX4k2wGDgdTMD6ALkmNkkd18ZYVwiDcL+I0FP4J++3pusXh1qvf5T2zajVbMof0VIXRHld3kF0NfMehMkgCuBq0sOuvs+oGPJtpm9TnCLqpKASDUM7dGe8YO7JDsMqcci6/e5exEwE1gEbACed/d1ZvagmU2Kql0REameeNYsNuAa4HR3f9DMMoAu7r68qs+6+8uUmY7C3e+roOx5cUUsIiK1Kp4ewWPAV4Grwu39BM8HiIhIAxDPGMEodz/TzFYBuPseM9MsVCIiDUQ8PYLC8Clhh9L1CKKfpFxERBIinh7Br4CFQGcz+08gG7g30qhEBIANn37JnGVb8XKentl3uPYfJJPUFM801HPM7D3gAoLpJS5z9w2RRyYi/P69XJ59dxsdW5d/NbZb+xZkdmqd4KikoYnnrqEM4BDwx9h97r4tysBEJLge27pZY1beOy7ZoUgDFs+loT8T/Dwa0BzoDXwEDIowLhERSZB4Lg0Nid0OJ4q7JbKIREQkoar9ZHE4/fSoKguKiEi9EM8YwZ0xm42AM4GdkUUkIiIJFc8YQZuY90UEYwa/jyYcERFJtEoTQfggWRt3/36C4hERkQSrMBGYWWN3LzKzryUyIJEozFm2lXtfXFvug1l1XdvmWhNAolXZT9hygvGA1WaWAywADpYcdPc/RBybSK3ZtOsATRo14jvnZSY7lGrr36VN1YVEaiCePzWaA/kEaxSXPE/ggBKB1CvNmjTiznH9kh2GSJ1TWSLoHN4xtJZ/JIAS9bCDLSIi5aksEaQBrTk+AZRQIhARaSAqSwSfuvuDCYtERESSorIni8vrCYiISANTWSK4IGFRiIhI0lR4acjddycyEEkdBUXF/PnDnRwqOJawNv/+6f6EtSVS3+hJFUm4FVt2c8f8NQlvt09nLeAiUh4lAkm4gmPBktdPXZ/F4NPaJazdti2aJKwtkfpEiUCS5pSWTenctnmywxBJedVej0BERBoWJQIRkRSnRCAikuKUCEREUpwSgYhIitNdQ/WMu3P7/NVs2nUg2aGctP1HipIdgojEiDQRmNl44JcEM5n+1t1/Uub4ncA/EayFnAfc6O5bo4ypIXhp9U5O79iK0zu1SnYoJ6VrOzir5yn0O1ULrojUBZElgnC940eBcUAusMLMctx9fUyxVUCWux8ys5uBnwJTooqpIZk07DRuv1CLrIhIzUU5RjAS2OTun7h7ATAPuDS2gLsvdfdD4ea7QPcI4xERkXJEmQi6AdtjtnPDfRWZDrxS3gEzm2FmK81sZV5eXi2GKCIideKuITO7FsgCHinvuLs/7u5Z7p7VqVOnxAYnItLARTlYvAPoEbPdPdx3HDO7ELgHGOPuRyOMR0REyhFlj2AF0NfMeptZU+BKICe2gJkNB34DTHL3XRHGIiIiFYgsEbh7ETATWARsAJ5393Vm9qCZTQqLPQK0BhaY2Wozy6mgOhERiUikzxG4+8vAy2X23Rfz/sIo22+IvgwfxvrysB7KEpHaUScGiyV+RwuD5R1Pa695/EWkdigR1FMtmqYlOwQRaSCUCEREUpwSgYhIilMiEBFJcUoEIiIpTolARCTFaWGaJMpZs5O3NlZvEr3D4e2jIiK1RYkgiR5buonNXxwkvVXTan2uZ3pLBnRtG1FUIpJqlAiSbEy/Tjw+NSvZYYhICtMYgYhIilMiEBFJcUoEIiIpTolARCTFKRGIiKQ43TUUMXen8JhXcCzBwYiIlEOJIGL3vriWOcu2VXj89E6tEhiNiMiJlAgitiX/IN3at+DqURnlHj+/f+cERyQicjwlggTo2q453x3bJ9lhiIiUS4PFIiIpTolARCTF6dKQSDkKCwvJzc3lyJEjyQ5FpFqaN29O9+7dadKkSdyfUSIQKUdubi5t2rShV69emFmywxGJi7uTn59Pbm4uvXv3jvtzujQkUo4jR46Qnp6uJCD1ipmRnp5e7Z5sSvUI1mzfy/vb9iS0zZ17j1R7vQGpG5QEpD46mZ/blEoE9764lg937Et4u0O6tUt4myIicXP3evU666yz/GRd/F9v+PVPLfM9B48m9HXsWPFJxyzJsX79+mSH4O7uCxcudMA3bNjg7u5Lly71Sy655Lgy06ZN8wULFri7e0FBgd99993ep08fHz58uI8ePdpffvnluNo6cuSIT5482TMzM33kyJG+efPmE8ocPnzYR4wY4WeccYYPHDjQ77vvvuPi6NWrlw8dOtSHDh3qq1atOu6zy5cv97S0tNJY3d1nzZrlffr08T59+visWbPc3f3LL78srWPo0KGenp7ut912m7u7//znP/cBAwb4kCFD/Pzzz/ctW7a4u/uqVat89OjRPnDgQB8yZIjPmzevtI1PPvnER44c6ZmZmT558mQ/evToSdd14403+hlnnOFDhgzxK664wvfv3+/u7lu2bPHzzz/fhwwZ4mPGjPHt27eXfmbr1q0+btw479+/vw8YMKD061pRXSVeeOEFB3zFihXuHnxvp06d6oMHD/b+/fv7j3/84wq/l+X9/AIrvYLfq0n/xV7dV00TwT/PXnHSn5fUUVcSweTJk/3rX/966S/cqhLB3Xff7VOnTvUjR464u/tnn33m8+fPj6utRx991G+66SZ3d587d65Pnjz5hDLFxcWlv7AKCgp85MiR/s4775wQR1lFRUU+duxYnzBhQmmZ/Px87927t+fn5/vu3bu9d+/evnv37hM+e+aZZ/obb7zh7u5LlizxgwcPurv7Y489VhrjRx995Bs3bnR39x07dniXLl18z5497u7+7W9/2+fOnevu7jfddJM/9thjJ13Xvn37SuO64447/KGHHnJ39+zs7NJE9pe//MWvvfba0nJjxozxxYsXu7v7/v37S9usqC73IBmec845PmrUqNJEMGfOHJ8yZYq7ux88eNB79uxZbrJ2r34iSKlLQyIn44E/rmP9zi9rtc6Bp7Xl3yYOqrTMgQMH+Otf/8rSpUuZOHEiDzzwQKXlDx06xBNPPMHmzZtp1qwZAKeeeiqTJ0+OK6aXXnqJ+++/H4Ds7GxmzpyJux93zdnMaN26NRDcYltYWBjXNelf//rXXHHFFaxYsaJ036JFixg3bhwdOnQAYNy4cbz66qtcddVVpWU2btzIrl27OOeccwAYO3Zs6bHRo0fz7LPPAtCvX7/S/aeddhqdO3cmLy+Pdu3asWTJEp577jkApk2bxv3338/NN99c7brat29P27bBWuHuzuHDh0vPff369fziF78ojfGyyy4r3V9UVMS4ceMASr92QIV1AfzoRz/i7rvv5pFHHindZ2YcPHiQoqIiDh8+TNOmTUvrqCndNSRSR7300kuMHz+efv36kZ6eznvvvVdp+U2bNpGRkVHhL4cpU6YwbNiwE15PP/00ADt27KBHjx4ANG7cmHbt2pGfn39CPceOHWPYsGF07tyZcePGMWrUqNJj99xzD2eccQZ33HEHR48eLa134cKF3HzzzcfVE9seQPfu3dmxY8dxZebNm8eUKVPKTTZPPvkkEyZMOGH/8uXLKSgoIDMzk/z8fNq3b0/jxo0rbCPeukrccMMNdOnShb///e/ceuutAAwdOpQ//OEPACxcuJD9+/eTn5/Pxo0bad++Pd/61rcYPnw4d911F8eOHau0rvfff5/t27dzySWXHBdLdnY2rVq1omvXrmRkZPD973+/NInWlHoEIlWo6i/3qMydO5fbbrsNgCuvvJK5c+cyceLEcsvG81f5/PnzayWutLQ0Vq9ezd69e7n88stZu3YtgwcP5qGHHqJLly4UFBQwY8YMHn74Ye677z5uv/12Hn74YRo1qv7fnfPmzeOZZ545Yf+zzz7LypUreeONN47b/+mnn3Ldddcxe/bsuNurbl2/+93vOHbsGLfeeivz58/nhhtu4Gc/+xkzZ85k1qxZnHvuuXTr1o20tDSKiop46623WLVqFRkZGUyZMoVZs2Yxffr0cuuaNm0ad955J7NmzTohzuXLl5OWlsbOnTvZs2cP55xzDhdeeCGnn356XOdZqYquGdXGCxgPfARsAn5QzvFmwPzw+DKgV1V1aoxAEiHZYwT5+fneokULz8jI8J49e3r37t29R48e/sEHH/jZZ599XNmJEyf666+/7gcPHvQOHTocd+051uTJk48bhC15zZ49293dL7roIn/77bfd3b2wsNDT09O9uLjyGx0eeOABf+SRR07YHzuW0atXL+/Zs6f37NnTW7Vq5Z06dfKFCxf6c8895zNmzCj9zIwZM/y5554r3V69erX37dv3hLpfe+0179+/v3/++efH7d+3b58PHz78uHGK4uJiT09P98LCQnd3f/vtt/2iiy46qbrKeuONN04Yr3EPxgG6devm7u7vvPOOn3vuuaXHnn76ab/lllsqrGvv3r2enp5e+vVq1qyZd+3a1VesWOG33HKLP/3006WfueGGGyoc/6nuGEFkl4bMLA14FJgADASuMrOBZYpNB/a4ex/gv4CHo4pHpD554YUXuO6669i6dStbtmxh+/bt9O7dm927d7Nz5042bNgAwNatW1mzZg3Dhg2jZcuWTJ8+ndtuu42CggIA8vLyWLBgARD0CFavXn3Ca+rUqQBMmjSJ2bNnl7Z//vnnn9DTyMvLY+/evQAcPnyY1157jf79+wPBX9AQ/HH54osvMnjwYAA2b97Mli1b2LJlC9nZ2Tz22GNcdtllXHzxxSxevJg9e/awZ88eFi9ezMUXX1za1ty5c48bLwBYtWoVN910Ezk5OXTu/I8p3AsKCrj88suZOnUq2dnZpfvNjLFjx/LCCy8AMHv2bC699NKTqsvd2bRpU+n7nJyc0nP/4osvKC4uBuChhx7ixhtvBGDEiBHs3buXvLw8AJYsWcLAgQMrrKtdu3Z88cUXpV+v0aNHk5OTQ1ZWFhkZGSxZsgSAgwcP8u6775a2X2MVZYiavoCvAotitn8I/LBMmUXAV8P3jYEvAKus3pPtEcxfvs173v0n9QgkLsnuEZx33nn+yiuvHLfvl7/8pX/nO9/xv/71rz5q1CgfOnSoZ2Vlld6R4u5+9OhRv+uuuzwzM9MHDRrkI0eO9FdffTWuNg8fPuzZ2dmemZnpI0aM8I8//tjdgztnJkyY4O7ua9as8WHDhvmQIUN80KBB/sADD5R+fuzYsT548GAfNGiQX3PNNSfcDul+4p1FTz75pGdmZnpmZqY/9dRTx5Xt3bt36W2zJS644ALv3LlzaW9m4sSJ7u7+zDPPeOPGjY/r6ZTcvvrxxx/7iBEjPDMz07Ozs0vvqKpuXceOHfOzzz679Byvvvrq0t7XggULvE+fPt63b1+fPn16aRvu7osXL/YhQ4b44MGDfdq0aX706NFK64o1ZsyY0ruG9u/f79nZ2T5w4EAfMGCA//SnP63we1ndHoEFx2ufmWUD4939n8Lt64BR7j4zpszasExuuP1xWOaLMnXNAGYAZGRknLV169Zqx7N43We8uHoH2Wd15/z+p57saUmK2LBhAwMGDEh2GCInpbyfXzN7z92zyitfLwaL3f1x4HGArKysk8pcFw3qwkWDutRqXCIiDUGUt4/uAHrEbHcP95VbxswaA+2AE+9XExGRyESZCFYAfc2st5k1Ba4EcsqUyQGmhe+zgSUe1bUqkWrSj6LURyfzcxtZInD3ImAmwYDwBuB5d19nZg+a2aSw2JNAupltAu4EfhBVPCLV0bx5c/Lz85UMpF5xD9YjaN68ebU+F9lgcVSysrJ85cqVyQ5DGjitUCb1VUUrlNX7wWKRRGvSpEm1VngSqc8015CISIpTIhARSXFKBCIiKa7eDRabWR5Q/UeLAx0JprFIJTrn1KBzTg01Oeee7t6pvAP1LhHUhJmtrGjUvKHSOacGnXNqiOqcdWlIRCTFKRGIiKS4VEsEjyc7gCTQOacGnXNqiOScU2qMQERETpRqPQIRESlDiUBEJMU1yERgZuPN7CMz22RmJ8xoambNzGx+eHyZmfVKQpi1Ko5zvtPM1pvZB2b2FzPrmYw4a1NV5xxT7gozczOr97caxnPOZjY5/F6vM7PnEh1jbYvjZzvDzJaa2arw5/sbyYiztpjZU2a2K1zBsbzjZma/Cr8eH5jZmTVutKI1LOvrC0gDPgZOB5oCa4CBZcrcAvxv+P5KYH6y407AOY8FWobvb06Fcw7LtQHeBN4FspIddwK+z32BVcAp4XbnZMedgHN+HLg5fD8Q2JLsuGt4zucCZwJrKzj+DeAVwIDRwLKattkQewQjgU3u/om7FwDzgEvLlLkUmB2+fwG4wMwsgTHWtirP2d2XuvuhcPNdghXj6rN4vs8A/w48DDSE+aTjOed/Bh519z0A7r4rwTHWtnjO2YG24ft2wM4Exlfr3P1NYHclRS4FnvbAu0B7M+takzYbYiLoBmyP2c4N95VbxoMFdPYB6QmJLhrxnHOs6QR/UdRnVZ5z2GXu4e5/TmRgEYrn+9wP6GdmfzOzd81sfMKii0Y853w/cK2Z5QIvA7cmJrSkqe7/9yppPYIUY2bXAlnAmGTHEiUzawT8Arg+yaEkWmOCy0PnEfT63jSzIe6+N5lBRewqYJa7/9zMvgo8Y2aD3b042YHVFw2xR7AD6BGz3T3cV24ZM2tM0J3MT0h00YjnnDGzC4F7gEnufjRBsUWlqnNuAwwGXjezLQTXUnPq+YBxPN/nXCDH3QvdfTOwkSAx1FfxnPN04HkAd38HaE4wOVtDFdf/9+poiIlgBdDXzHqbWVOCweCcMmVygGnh+2xgiYejMPVUledsZsOB3xAkgfp+3RiqOGd33+fuHd29l7v3IhgXmeTu9Xmd03h+tl8k6A1gZh0JLhV9ksAYa1s857wNuADAzAYQJIK8hEaZWDnA1PDuodHAPnf/tCYVNrhLQ+5eZGYzgUUEdxw85e7rzOxBYKW75wBPEnQfNxEMylyZvIhrLs5zfgRoDSwIx8W3ufukpAVdQ3Gec4MS5zkvAi4ys/XAMeAud6+3vd04z/l7wBNmdgfBwPH19fkPOzObS5DMO4bjHv8GNAFw9/8lGAf5BrAJOATcUOM26/HXS0REakFDvDQkIiLVoEQgIpLilAhERFKcEoGISIpTIhARSXFKBFInmdkxM1sd8+pVSdkDtdDeLDPbHLb1fviEanXr+K2ZDQzf/2uZY2/XNMawnpKvy1oz+6OZta+i/LD6PhunRE+3j0qdZGYH3L11bZetpI5ZwJ/c/QUzuwj4mbufUYP6ahxTVfWa2Wxgo7v/ZyXlryeYdXVmbcciDYd6BFIvmFnrcB2F983sQzM7YaZRM+tqZm/G/MV8Trj/IjN7J/zsAjOr6hf0m0Cf8LN3hnWtNbPbw32tzOzPZrYm3D8l3P+6mWWZ2U+AFmEcc8JjB8J/55nZJTExzzKzbDNLM7NHzGxFOMf8TXF8Wd4hnGzMzEaG57jKzN42s6+ET+I+CEwJY5kSxv6UmS0Py5Y3Y6ukmmTPva2XXuW9CJ6KXR2+FhI8Bd82PNaR4KnKkh7tgfDf7wH3hO/TCOYb6kjwi71VuP9u4L5y2psFZIfvvw0sA84CPgRaETyVvQ4YDlwBPBHz2Xbhv68TrnlQElNMmZIYLwdmh++bEswi2QKYAdwb7m8GrAR6lxPngZjzWwCMD7fbAo3D9xcCvw/fXw/8d8znfwxcG75vTzAXUatkf7/1Su6rwU0xIQ3GYXcfVrJhZk2AH5vZuUAxwV/CpwKfxXxmBfBUWPZFd19tZmMIFiv5Wzi1RlOCv6TL84iZ3UswT810gvlrFrr7wTCGPwDnAK8CPzezhwkuJ71VjfN6BfilmTUDxgNvuvvh8HLUGWaWHZZrRzBZ3OYyn29hZqvD898AvBZTfraZ9SWYZqFJBe1fBEwys++H282BjLAuSVFKBFJfXAN0As5y90ILZhRtHlvA3d8ME8UlwCwz+wWwB3jN3a+Ko4273P2Fkg0zu6C8Qu6+0YK1Dr4B/IeZ/cXdH4znJNz9iJm9DlwMTCFYaAWC1aZudfdFVVRx2N2HmVlLgvl3vgv8imABnqXufnk4sP56BZ834Ap3/yieeCU1aIxA6ot2wK4wCYwFTlhz2YJ1mD939yeA3xIs9/cu8DUzK7nm38rM+sXZ5lvAZWbW0sxaEVzWecvMTgMOufuzBJP5lbdmbGHYMynPfIKJwkp6FxD8Ur+55DNm1i9ss1werDb3L8D37B9TqZdMRXx9TNH9BJfISiwCbrWwe2TBrLSS4pQIpL6YA2SZ2YfAVODv5ZQ5D1hjZqsI/tr+pbvnEfxinGtmHxBcFuofT4Pu/j7B2MFygjGD37r7KmAIsDy8RPNvwH+U8/HHgQ9KBovLWEywMND/9WD5RQgS13rgfQsWLf8NVfTYw1g+IFiY5afAQ+G5x35uKTCwZLCYoOfQJIxtXbgtKU63j4qIpDj1CEREUpwSgYhIilMiEBFJcUoEIiIpTolARCTFKRGIiKQ4JQIRkRT3/wF51Qx5aZK8QAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "p = 0.01  # 1% of the lines\n",
    "# keep the header, then take only 1% of lines\n",
    "# if random from [0,1] interval is greater than 0.01 the row will be skipped\n",
    "data = pd.read_csv(\n",
    "         \"classdata.csv\",\n",
    "         header=0, \n",
    "         skiprows=lambda i: i>0 and random.random() > p\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Checking correlation\n",
    "correlation = data.corr()\n",
    "# print(correlation[\"isFraud\"].sort_values(ascending=False))\n",
    "\n",
    "data[\"type\"] = data[\"type\"].map({\"CASH_OUT\": 1, \"PAYMENT\": 2,\"CASH_IN\": 3, \"TRANSFER\": 4,\"DEBIT\": 5})\n",
    "data[\"isFraud\"] = data[\"isFraud\"].map({0: \"No Fraud\", 1: \"Fraud\"})#string to integers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data.drop(['nameOrig','nameDest'],axis=1,inplace=True)\n",
    "X=data.drop('isFraud',axis=1)\n",
    "y=data['isFraud']\n",
    "for i in range(1,7):\n",
    "    max_X=max(X.iloc[:,i])\n",
    "    min_X=min(X.iloc[:,i])\n",
    "    X.iloc[:,i]=(X.iloc[:,i]-min_X)/(max_X-min_X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_cv, X_test_new=np.split(X_test, 2)\n",
    "Y_cv , Y_test_new=np.split(y_test, 2)\n",
    "\n",
    "y_train_new=np.zeros(len(y_train))\n",
    "for i in range (len(y_train)):\n",
    "    if y_train.iloc[i] == 'Fraud':\n",
    "        y_train_new[i] =1  \n",
    "y_train_new=pd.DataFrame(y_train_new)\n",
    "Y_cv_new=np.zeros(len(Y_cv))\n",
    "for i in range (len(Y_cv)):\n",
    "    if Y_cv.iloc[i] == 'Fraud':\n",
    "        Y_cv_new[i] =1  \n",
    "Y_test_new_1=np.zeros(len(Y_cv))\n",
    "for i in range (len(Y_test_new)):\n",
    "    if Y_test_new.iloc[i] == 'Fraud':\n",
    "        Y_test_new_1[i] =1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def generateXvector(X):#add coloumn of 1 in X features\n",
    "    \"\"\" Taking the original independent variables matrix and add a row of 1 which corresponds to x_0\n",
    "        Parameters:\n",
    "          X:  independent variables matrix\n",
    "        Return value: the matrix that contains all the values in the dataset, not include the outcomes variables.  \"\"\"\n",
    "    vectorX = np.c_[np.ones((len(X), 1)), X]\n",
    "    return vectorX\n",
    "def theta_init(X):\n",
    "    \"\"\" Generate an initial value of vector Î¸ from the original independent variables matrix\n",
    "         Parameters:\n",
    "          X:  independent variables matrix\n",
    "        Return value: a vector of theta filled with initial guess\n",
    "    \"\"\"\n",
    "    theta = np.random.randn(X+1, 1)\n",
    "    return theta\n",
    "\n",
    "def sigmoid_function(X):\n",
    "    \"\"\" Calculate the sigmoid value of the inputs\n",
    "         Parameters:\n",
    "          X:  values\n",
    "        Return value: the sigmoid value\n",
    "    \"\"\"\n",
    "    return 1/(1+math.e**(-X))\n",
    "def Logistics_Regression(X,y,learningrate, iterations):\n",
    "        \n",
    "    y_new = y\n",
    "    cost_lst = []\n",
    "    vectorX = generateXvector(X)\n",
    "    theta = theta_init(len(X.iloc[0,:]))\n",
    "    m = len(X)\n",
    "    for i in range(iterations):\n",
    "        gradients = 2/m * vectorX.T.dot(sigmoid_function(vectorX.dot(theta)) - y_new)\n",
    "        theta = theta - learningrate * gradients\n",
    "        y_pred = sigmoid_function(vectorX.dot(theta))\n",
    "        cost_value = - np.sum(np.dot(y_new.T,np.log(y_pred)+ np.dot((1-y_new).T,np.log(1-y_pred)))) /(len(y_pred))\n",
    " #Calculate the loss for each training instance\n",
    "        cost_lst.append(cost_value)\n",
    "        \n",
    "    # plt.plot(np.arange(1,iterations),cost_lst[1:], color = 'red')\n",
    "    # plt.title('Cost function Graph')\n",
    "    # plt.xlabel('Number of iterations')\n",
    "    # plt.ylabel('Cost')\n",
    "    return theta, cost_value\n",
    "\n",
    "theta1, cost_value1=Logistics_Regression(X_train,y_train_new,0.03, 100)\n",
    "def root_regularization(y_pred,y_test,theta):\n",
    "    cost_reg=100\n",
    "    best_lamda=0\n",
    "    lamda=np.array([0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24])\n",
    "    cost_lst = []\n",
    "    m = len(X)\n",
    "    N = len(y_test)\n",
    "    for l in range(np.size(lamda)):\n",
    "        term=(lamda[l]/2*N)*(np.sum(theta**2))\n",
    "        cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))+term\n",
    "        cost_lst.append(cost_value)\n",
    "        if cost_value<cost_reg:\n",
    "            cost_reg=cost_value\n",
    "            best_lamda=lamda[l]\n",
    "    return best_lamda,cost_reg\n",
    "\n",
    "def rmse(y_pred,y_test):\n",
    "    cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))\n",
    "    return cost_value\n",
    "\n",
    "cost_cv=100\n",
    "theta1_cv=[]\n",
    "for j in range(9):#cross validation\n",
    "    vectorX=generateXvector(X_cv.iloc[:,0:j])\n",
    "    theta2, cost_value1=Logistics_Regression(X_train.iloc[:,0:j],y_train_new,0.03, 100)\n",
    "   \n",
    "    y_pred = sigmoid_function(vectorX.dot(theta2))#calculate hypothesis using best thetas\n",
    "    best_lamda,cost_reg=root_regularization(y_pred,Y_cv_new,theta2)\n",
    "    if cost_value1<cost_cv:\n",
    "        cost_cv=cost_value1\n",
    "        theta1_cv=theta2\n",
    "    if cost_reg<cost_cv:\n",
    "        cost_cv=cost_reg\n",
    "        theta1_cv=theta2\n",
    "y_pred_test=sigmoid_function(np.dot(X_test_new.iloc[:,0:np.size(theta1_cv)], theta1_cv))\n",
    "cost_Y_test=rmse(y_pred_test,Y_test_new_1)\n",
    "cost_test_reg=rmse(y_pred_test,Y_test_new_1)+(best_lamda/2*len(Y_cv))*(np.sum(theta1_cv**2))\n",
    "##K fold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "skfolds = KFold(n_splits=10)\n",
    "splits = skfolds.split(X, y)\n",
    "for i, (train_index, test_index) in enumerate(splits): #split and shuffle the data  \n",
    "  x_train = X.iloc[train_index]\n",
    "  y_train = y.iloc[train_index]\n",
    "  x_test  = X.iloc[test_index]\n",
    "  y_test  = y.iloc[test_index]\n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_pred = clf.predict(x_test)\n",
    "  accuracy = np.mean(y_pred == y_test)\n",
    "  print(accuracy,'accuracy per iteration')\n",
    "##stratified\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfolds_1 = StratifiedKFold(n_splits=9)\n",
    "splits_1 = skfolds_1.split(X, y)\n",
    "for i, (train_index, test_index) in enumerate(splits_1): #split and shuffle the data \n",
    "  x_train = X.iloc[train_index]\n",
    "  y_train = y.iloc[train_index]\n",
    "  x_test  = X.iloc[test_index]\n",
    "  y_test  = y.iloc[test_index]\n",
    "  clf_1 = LogisticRegression()\n",
    "  clf_1.fit(x_train, y_train)\n",
    "  y_pred_1 = clf_1.predict(x_test)\n",
    "  accuracy = np.mean(y_pred_1 == y_test)\n",
    "  print(\"Accuracy: %.4f\"%accuracy)\n",
    "  print(\"[SPLIT %d]\"%(i+1))\n",
    "# print(\"Percentage of digit 9 in the original dataset: %.2f %%\"%(np.mean(y==True)*100))\n",
    "# print(\"Percentage of digit 9 in the training set: %.2f %%\"%(np.mean(y_train==True)*100))\n",
    "# print(\"Percentage of digit 9 in the test set: %.2f %%\"%(np.mean(y_test==True)*100))\n",
    "# print(\"Accuracy: %.4f\"%accuracy)\n",
    "#conv matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "print(sklearn.metrics.confusion_matrix(Y_test_new_1,np.round((y_pred_test))))\n",
    "print(accuracy_score(Y_test_new_1, np.round((y_pred_test))) )\n",
    "##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test_new_1,  y_pred_test)#represents the relation between TP and FP\n",
    "auc = metrics.roc_auc_score(Y_test_new_1, y_pred_test)\n",
    "\n",
    "#create ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc446a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
